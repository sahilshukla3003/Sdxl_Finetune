2025-11-19 15:04:41 - INFO - Configuration saved
2025-11-19 15:04:41 - INFO - Memory optimization mode: Target 8-10GB VRAM
2025-11-19 15:04:41 - INFO - Accelerator device: cuda
2025-11-19 15:04:41 - INFO - Mixed precision: fp16
2025-11-19 15:04:41 - INFO - Loading tokenizers...
2025-11-19 15:04:44 - INFO - Loading noise scheduler...
2025-11-19 15:04:44 - INFO - Loading VAE...
2025-11-19 15:04:53 - INFO - ✓ VAE loaded
2025-11-19 15:04:53 - INFO - Loading text encoders...
2025-11-19 15:06:23 - INFO - ✓ Text encoders loaded
2025-11-19 15:06:23 - INFO - Loading UNet...
2025-11-19 15:11:01 - INFO - ✓ Gradient checkpointing enabled
2025-11-19 15:11:01 - INFO - ✓ SDPA attention enabled
2025-11-19 15:11:01 - INFO - ✓ UNet loaded
2025-11-19 15:11:01 - INFO - Applying LoRA (rank=8)...
2025-11-19 15:11:02 - INFO - ✓ LoRA applied
2025-11-19 15:11:02 - INFO - Loading dataset: lambdalabs/naruto-blip-captions
2025-11-19 15:11:33 - INFO - Dataset loaded: 1221 images
2025-11-19 15:11:33 - INFO - Caching latents for 1221 images at 768x768...
2025-11-19 15:12:57 - INFO - ✓ Latent caching complete
2025-11-19 15:12:57 - INFO - ✓ Dataloader ready: 1221 training samples
2025-11-19 15:12:57 - INFO - Pre-computing and caching text embeddings to disk...
2025-11-19 15:13:33 - INFO - ✓ Text embeddings cached to disk, encoders moved to CPU
2025-11-19 15:13:33 - INFO - ✓ VAE offloaded
2025-11-19 15:13:33 - INFO - ✓ Optimizer and scheduler configured
2025-11-19 15:13:35 - INFO - ================================================================================
2025-11-19 15:13:35 - INFO - STARTING TRAINING - MEMORY OPTIMIZED MODE
2025-11-19 15:13:35 - INFO - ================================================================================
2025-11-19 15:13:35 - INFO -   Num examples: 1221
2025-11-19 15:13:35 - INFO -   Num epochs: 15
2025-11-19 15:13:35 - INFO -   Batch size: 1
2025-11-19 15:13:35 - INFO -   Gradient accumulation: 8
2025-11-19 15:13:35 - INFO -   Total steps: 3000
2025-11-19 15:13:35 - INFO -   Resolution: 768x768
2025-11-19 15:13:35 - INFO -   LoRA rank: 8
2025-11-19 15:13:35 - INFO -   Learning rate: 0.0001
2025-11-19 15:13:35 - INFO -   EMA: Disabled (memory saving)
2025-11-19 15:13:35 - INFO - ================================================================================
